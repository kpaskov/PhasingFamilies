{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0aad2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from os import listdir\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14caf6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../DATA/platinum'\n",
    "ped_file = '../../DATA/platinum/platinum.ped.quads.ped'\n",
    "chroms = [str(x) for x in range(1, 23)]\n",
    "haplotype_file = '../data/GenotypeFiles/haplotype_transmission_hg19.txt'\n",
    "\n",
    "#data_dir = '../../DATA/platinum_sim'\n",
    "#ped_file = '../../DATA/platinum_sim/sim_platinum.ped'\n",
    "#chroms = ['10']\n",
    "#haplotype_file = '../simulation/simulated_genomes/simulated_haplotype_transmission_hg19.txt'\n",
    "\n",
    "gens = ['0/0', '0/1', '1/1']\n",
    "obss = ['0/0', '0/1', '1/1', './.']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e9ac3b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/genotypes/info.json' % data_dir, 'r') as f:\n",
    "\tassembly = json.load(f)['assembly']\n",
    "    \n",
    "sample_file = '%s/genotypes/samples.json' % data_dir\n",
    "# pull samples\n",
    "with open(sample_file, 'r') as f:\n",
    "\tindividuals = json.load(f)\n",
    "sample_id_to_index = dict([(sample_id, i) for i, sample_id in enumerate(individuals)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ebff4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "children = set()\n",
    "ind_to_fams = defaultdict(list)\n",
    "\n",
    "with open(ped_file, 'r') as f:\t\n",
    "    for line in f:\n",
    "        pieces = line.strip().split('\\t')\n",
    "        if len(pieces) < 4:\n",
    "            print('ped parsing error', line)\n",
    "        else:\n",
    "            fam_id = pieces[0]\n",
    "            child_id, f_id, m_id = [x.replace('.', '_') for x in pieces[1:4]]\n",
    "            if f_id != '0' and m_id != '0':\n",
    "                children.add('%s.%s' % (fam_id, child_id))\n",
    "            ind_to_fams[child_id].append(fam_id)\n",
    "            ind_to_fams[m_id].append(fam_id)\n",
    "            ind_to_fams[f_id].append(fam_id)\n",
    "def is_child(ind_id):\n",
    "    return ind_id in children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c6dad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_gen_data_for_individuals(data_dir, chrom, start_pos=None, end_pos=None, use_pass=False):\n",
    "\n",
    "\t# pull coordinates\n",
    "\t# use only SNPs, no indels\n",
    "\t# use only variants that PASS GATK\n",
    "\t# pull data only for individuals\n",
    "\tm = len(individuals)\n",
    "\thas_seq = np.array(np.where([x in sample_id_to_index for x in individuals])[0].tolist())\n",
    "\tind_indices = [sample_id_to_index[x] for x in individuals if x in sample_id_to_index]\n",
    "\n",
    "\tif len(ind_indices)==0:\n",
    "\t\treturn np.zeros((m, 0)), np.zeros((0, 2)), np.zeros((0,)) \n",
    "\n",
    "\n",
    "\tgen_files = sorted([f for f in listdir('%s/genotypes' % data_dir) if ('chr.%s.' % chrom) in f and 'gen.npz' in f], key=lambda x: int(x.split('.')[2]))\n",
    "\tcoord_files = sorted([f for f in listdir('%s/genotypes' % data_dir) if ('chr.%s.' % chrom) in f and 'gen.coordinates.npy' in f], key=lambda x: int(x.split('.')[2]))\n",
    "\t#af_files = sorted([f for f in listdir(data_dir) if ('chr.%s.' % chrom) in f and 'gen.af.npy' in f], key=lambda x: int(x.split('.')[2]))\n",
    "\n",
    "\t#print(len(gen_files), len(coord_files))\n",
    "\tassert len(gen_files) == len(coord_files)\n",
    "\t#assert len(gen_files) == len(af_files)\n",
    "\n",
    "\t# pull chrom length\n",
    "\tassert assembly == '37' or assembly == '38'\n",
    "\twith open('../data/chrom_lengths%s.json' % assembly, 'r') as f:     \n",
    "\t\tchrom_length = json.load(f)[chrom]\n",
    "\n",
    "\tgens, snp_positions, collapseds = [], [], []\n",
    "\ttotal_pos = 0\n",
    "\tfor gen_file, coord_file in zip(gen_files, coord_files):\n",
    "\t\tcoords = np.load('%s/genotypes/%s' % (data_dir, coord_file))\n",
    "\n",
    "\t\tif coords.shape[0]>0:\n",
    "\t\t\tposs = coords[:, 1]\n",
    "\t\t\tis_snp = coords[:, 2]==1\n",
    "\t\t\tis_pass = coords[:, 3]==1\n",
    "\n",
    "\t\t\tif not use_pass:\n",
    "\t\t\t\tis_pass = np.ones(is_pass.shape, dtype=bool)\n",
    "\n",
    "\t\t\t# remove multiallelic sites\n",
    "\t\t\tmulti_indices = np.where(coords[1:, 1]==coords[:-1, 1])[0]\n",
    "\t\t\tis_pass[multi_indices] = False\n",
    "\t\t\tis_pass[multi_indices+1] = False\n",
    "\n",
    "\t\t\tif start_pos is not None and end_pos is not None:\n",
    "\t\t\t\tin_interval = (coords[:, 1]>=start_pos) & (coords[:, 1]<=end_pos)\n",
    "\t\t\telse:\n",
    "\t\t\t\tin_interval = np.ones((is_snp.shape[0],), dtype=bool)\n",
    "\n",
    "\t\t\tif np.sum(is_snp & is_pass & in_interval)>0:\n",
    "\t\t\t\tgen = sparse.load_npz('%s/genotypes/%s' % (data_dir, gen_file))[ind_indices, :]\n",
    "\t\t\t\ttotal_pos += np.sum(is_snp & is_pass)\n",
    "\t\t\t\tfamily_has_variant = ((gen>0).sum(axis=0)>0).A.flatten()\n",
    "\n",
    "\t\t\t\thas_data = np.where(is_snp & is_pass & in_interval & family_has_variant)[0]\n",
    "\n",
    "\t\t\t\tif len(has_data)>0:\n",
    "\t\t\t\t\n",
    "\t\t\t\t\t# count the number of observed sites in between snps with data\n",
    "\t\t\t\t\tc = np.cumsum(is_snp & is_pass & in_interval & ~family_has_variant)\n",
    "\t\t\t\t\tcollapsed = np.zeros((len(has_data),), dtype=int)\n",
    "\t\t\t\t\tcollapsed_front = c[has_data[0]]\n",
    "\t\t\t\t\tcollapsed[:-1] = c[has_data][1:]-c[has_data][:-1]\n",
    "\t\t\t\t\tcollapsed[-1] = c[-1]-c[has_data[-1]]\n",
    "\t\t\t\t\t#print(c[-1]+len(has_data), np.sum(is_snp & is_pass), np.sum(collapsed)+len(has_data)+collapsed_front)\n",
    "\n",
    "\t\t\t\t\tif len(collapseds) == 0:\n",
    "\t\t\t\t\t\tcollapseds.append([collapsed_front])\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tcollapseds[-1][-1] += collapsed_front\n",
    "\n",
    "\t\t\t\t\tgens.append(gen[:, has_data].A)\n",
    "\t\t\t\t\tsnp_positions.append(poss[has_data])\n",
    "\t\t\t\t\t#afs.append(np.digitize(-np.log10(np.clip(af[has_data], 10**-(af_boundaries[0]+1), None)), af_boundaries))\n",
    "\t\t\t\t\tcollapseds.append(collapsed)\n",
    "\n",
    "\n",
    "\tif len(gens)== 0:\n",
    "\t\treturn np.zeros((m, 0)), np.zeros((0, 2)), np.zeros((0,))\n",
    "\n",
    "\tgens = np.hstack(gens)\n",
    "\tsnp_positions = np.hstack(snp_positions)\n",
    "\tcollapseds = np.hstack(collapseds)\n",
    "\n",
    "\tassert np.all(snp_positions <= chrom_length)\n",
    "\tassert np.all(snp_positions[1:]>=snp_positions[:-1])\n",
    "\tassert np.all(collapseds >= 0)\n",
    "\n",
    "\tn = 2*len(snp_positions)+1\n",
    "\tfamily_genotypes = np.zeros((len(has_seq), n), dtype=np.int8)\n",
    "\tfamily_genotypes[:, np.arange(1, n-1, 2)] = gens\n",
    "\t\t\n",
    "\tobserved = np.zeros((n,), dtype=int)\n",
    "\tobserved[np.arange(1, n-1, 2)] = 1\n",
    "\tobserved[np.arange(0, n, 2)] = collapseds\n",
    "\t\t\n",
    "\tfamily_snp_positions = np.zeros((n, 2), dtype=int)\n",
    "\tfamily_snp_positions[np.arange(1, n-1, 2), 0] = snp_positions\n",
    "\tfamily_snp_positions[np.arange(1, n-1, 2), 1] = snp_positions+1\n",
    "\n",
    "\tfamily_snp_positions[np.arange(0, n-2, 2), 1] = snp_positions\n",
    "\tfamily_snp_positions[np.arange(2, n, 2), 0] = snp_positions+1\n",
    "\tfamily_snp_positions[0, 0] = 1\n",
    "\tfamily_snp_positions[-1, 1] = chrom_length\n",
    "\n",
    "\tassert np.all(family_snp_positions[:, 1] >= family_snp_positions[:, 0])\n",
    "\n",
    "\t# remove unnecessary intervals\n",
    "\thaslength = np.where(family_snp_positions[:, 0]!=family_snp_positions[:, 1])[0]\n",
    "\tfamily_genotypes = family_genotypes[:, haslength]\n",
    "\tfamily_snp_positions = family_snp_positions[haslength, :]\n",
    "\tobserved = observed[haslength]\n",
    "\n",
    "\t# aggregate identical genotypes\n",
    "\trep_indices = np.where(np.any(family_genotypes[:, 1:]!=family_genotypes[:, :-1], axis=0))[0]\n",
    "\tn = rep_indices.shape[0]+1\n",
    "\t#print('n', n)\n",
    "\n",
    "\tnew_family_genotypes = np.zeros((m, n), dtype=np.int8)\n",
    "\tmult_factor = np.zeros((n,), dtype=int)\n",
    "\n",
    "\tnew_family_genotypes[np.ix_(has_seq, np.arange(n-1))] = family_genotypes[:, rep_indices]\n",
    "\tnew_family_genotypes[has_seq, -1] = family_genotypes[:, -1]\n",
    "\n",
    "\tnew_family_snp_positions = np.zeros((n, 2), dtype=int)\n",
    "\tnew_family_snp_positions[0, 0] = family_snp_positions[0, 0]\n",
    "\tnew_family_snp_positions[:-1, 1] = family_snp_positions[rep_indices, 1]\n",
    "\tnew_family_snp_positions[1:, 0] = family_snp_positions[rep_indices+1, 0]\n",
    "\tnew_family_snp_positions[-1, 1] = family_snp_positions[-1, 1]\n",
    "\n",
    "\t#print(new_family_snp_positions)\n",
    "\n",
    "\tc = np.cumsum(observed)\n",
    "\tif len(rep_indices)==0:\n",
    "\t\tmult_factor[0] = np.sum(observed)\n",
    "\telse:\n",
    "\t\tmult_factor[0] = c[rep_indices[0]]\n",
    "\t\tmult_factor[1:-1] = c[rep_indices[1:]] - c[rep_indices[:-1]]\n",
    "\t\tmult_factor[-1] = c[-1] - c[rep_indices[-1]]\n",
    "\t#print(c[-1], np.sum(mult_factor))\n",
    "\t#assert np.all(mult_factor>=0)\n",
    "\n",
    "\tprint('genotypes pulled', new_family_genotypes.shape)\n",
    "\t#print(mult_factor)\n",
    "\n",
    "\treturn new_family_genotypes, new_family_snp_positions, mult_factor, individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90394a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bedfile(bed_file, chrom, offset=0):\n",
    "    regions = []\n",
    "    coverage = 0\n",
    "    with open(bed_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if '\\t' in line.strip():\n",
    "                pieces = line.strip().split('\\t')[offset:]\n",
    "            else:\n",
    "                pieces = line.strip().split(':')\n",
    "                pieces = [pieces[0]] + pieces[1].strip().split('-')\n",
    "\n",
    "            if pieces[0] == chrom or pieces[0] == 'chr%s' % chrom:\n",
    "                regions.append(int(pieces[1]))\n",
    "                regions.append(int(pieces[2])+1)\n",
    "                coverage += (int(pieces[2])+1 - int(pieces[1]))\n",
    "    return np.array(regions), coverage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "774182fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "genotypes pulled (13, 761130)\n",
      "missing 1283\n",
      "no inh 141\n",
      "20722\n",
      "2\n",
      "genotypes pulled (13, 790262)\n",
      "missing 1587\n",
      "no inh 115\n",
      "16085\n",
      "3\n",
      "genotypes pulled (13, 664041)\n",
      "missing 2677\n",
      "no inh 96\n",
      "9329\n",
      "4\n",
      "genotypes pulled (13, 715588)\n",
      "missing 2117\n",
      "no inh 80\n",
      "14777\n",
      "5\n",
      "genotypes pulled (13, 595848)\n",
      "missing 1430\n",
      "no inh 79\n",
      "5462\n",
      "6\n",
      "genotypes pulled (13, 633392)\n",
      "missing 2353\n",
      "no inh 60\n",
      "10092\n",
      "7\n",
      "genotypes pulled (13, 559632)\n",
      "missing 849\n",
      "no inh 72\n",
      "13094\n",
      "8\n",
      "genotypes pulled (13, 508264)\n",
      "missing 2627\n",
      "no inh 79\n",
      "3895\n",
      "9\n",
      "genotypes pulled (13, 436867)\n",
      "missing 340\n",
      "no inh 70\n",
      "16129\n",
      "10\n",
      "genotypes pulled (13, 485256)\n",
      "missing 622\n",
      "no inh 70\n",
      "8241\n",
      "11\n",
      "genotypes pulled (13, 488173)\n",
      "missing 2600\n",
      "no inh 54\n",
      "5261\n",
      "12\n",
      "genotypes pulled (13, 456194)\n",
      "missing 960\n",
      "no inh 63\n",
      "4705\n",
      "13\n",
      "genotypes pulled (13, 365903)\n",
      "missing 399\n",
      "no inh 53\n",
      "3978\n",
      "14\n",
      "genotypes pulled (13, 301898)\n",
      "missing 789\n",
      "no inh 45\n",
      "4750\n",
      "15\n",
      "genotypes pulled (13, 285210)\n",
      "missing 395\n",
      "no inh 58\n",
      "4661\n",
      "16\n",
      "genotypes pulled (13, 306744)\n",
      "missing 1566\n",
      "no inh 58\n",
      "14082\n",
      "17\n",
      "genotypes pulled (13, 266345)\n",
      "missing 340\n",
      "no inh 58\n",
      "7369\n",
      "18\n",
      "genotypes pulled (13, 276192)\n",
      "missing 560\n",
      "no inh 55\n",
      "3252\n",
      "19\n",
      "genotypes pulled (13, 218758)\n",
      "missing 1400\n",
      "no inh 49\n",
      "4879\n",
      "20\n",
      "genotypes pulled (13, 213600)\n",
      "missing 378\n",
      "no inh 42\n",
      "7760\n",
      "21\n",
      "genotypes pulled (13, 157664)\n",
      "missing 66\n",
      "no inh 27\n",
      "12915\n",
      "22\n",
      "genotypes pulled (13, 129356)\n",
      "missing 457\n",
      "no inh 43\n",
      "4709\n"
     ]
    }
   ],
   "source": [
    "lcr_num = np.zeros((len(individuals), 3, 4))\n",
    "lcr_denom = np.zeros((len(individuals), 3, 4))\n",
    "hcr_num = np.zeros((len(individuals), 3, 4))\n",
    "hcr_denom = np.zeros((len(individuals), 3, 4))\n",
    "    \n",
    "for chrom in chroms:\n",
    "    print(chrom)\n",
    "    gen, pos, mult, individuals = pull_gen_data_for_individuals(data_dir, chrom)\n",
    "    gen[gen==-1] = 3\n",
    "    print('missing', np.sum(gen==3))\n",
    "    \n",
    "    # which variants are in LCR?\n",
    "    lcr_regions, _ = process_bedfile('../data/btu356-suppl_data/btu356_LCR-hs37d5.bed/btu356_LCR-hs37d5.bed', chrom)\n",
    "    insert_loc = np.searchsorted(lcr_regions, pos[:, 0])\n",
    "    is_lcr = np.remainder(insert_loc, 2)==1\n",
    "    \n",
    "    # pull platinum inheritance pattern\n",
    "    inheritance_vector = np.zeros((4, len(individuals), gen.shape[1]), dtype=int)\n",
    "    inh_is_known = np.zeros((gen.shape[1],), dtype=bool)\n",
    "\n",
    "    with open(haplotype_file, 'r') as f:\n",
    "        next(f) # skip header\n",
    "        for line in f:\n",
    "            pieces = line.strip().split()\n",
    "            ch = pieces[0][3:]\n",
    "            if ch == chrom:\n",
    "                start_pos, end_pos = int(pieces[1]), int(pieces[2])\n",
    "                inh_is_known[(start_pos <= pos[:, 0]) & (pos[:, 1] <= end_pos)] = True\n",
    "                for i, inh in enumerate(pieces[3:]):\n",
    "                    inheritance_vector[0, i, (start_pos <= pos[:, 0]) & (pos[:, 1] <= end_pos)] = 'A' in inh\n",
    "                    inheritance_vector[1, i, (start_pos <= pos[:, 0]) & (pos[:, 1] <= end_pos)] = 'B' in inh\n",
    "                    inheritance_vector[2, i, (start_pos <= pos[:, 0]) & (pos[:, 1] <= end_pos)] = 'C' in inh\n",
    "                    inheritance_vector[3, i, (start_pos <= pos[:, 0]) & (pos[:, 1] <= end_pos)] = 'D' in inh\n",
    "\n",
    "    # what are the parental variants?\n",
    "    anc_variants = np.array([x for x in product([0, 1], repeat=4)])\n",
    "    possible_famgens = np.tensordot(anc_variants, inheritance_vector, axes=(1, 0))\n",
    "    num_mismatches = np.sum((possible_famgens != np.tile(gen, (16, 1, 1))) & (np.tile(gen, (16, 1, 1)) != 3), axis=1)\n",
    "    best_anc = np.argmin(num_mismatches, axis=0)\n",
    "    best_fit = num_mismatches[best_anc, np.arange(gen.shape[1])]\n",
    "    num_fits = np.sum(num_mismatches == np.tile(best_fit, (16, 1)), axis=0)\n",
    "    is_good_fit = inh_is_known\n",
    "    true_gen = possible_famgens[best_anc, :, np.arange(gen.shape[1])].T\n",
    "    print('no inh', np.sum(~inh_is_known))\n",
    "    #print('bad fit', np.sum(best_fit>2))\n",
    "    print(np.sum(is_good_fit & (best_fit != 0)))\n",
    "    \n",
    "    # calculate error rates\n",
    "    \n",
    "    for j in range(len(individuals)):\n",
    "        for g in range(len(gens)):\n",
    "            for obs in range(len(obss)):\n",
    "                lcr_num[j, g, obs] += np.sum(1/num_fits[is_good_fit & is_lcr & (true_gen[j, :]==g) & (gen[j, :]==obs)])\n",
    "                lcr_denom[j, g, obs] += np.sum(1/num_fits[is_good_fit & is_lcr & (true_gen[j, :]==g) & (gen[j, :]!=3)])\n",
    "                hcr_num[j, g, obs] += np.sum(1/num_fits[is_good_fit & ~is_lcr & (true_gen[j, :]==g) & (gen[j, :]==obs)])\n",
    "                hcr_denom[j, g, obs] += np.sum(1/num_fits[is_good_fit & ~is_lcr & (true_gen[j, :]==g) & (gen[j, :]!=3)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef1db07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "print(lcr_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d29858f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write error rate estimates\n",
    "with open('%s/sequencing_error_rates/LCR_errors.json' % data_dir, 'w+') as f:\n",
    "    error_rates = defaultdict(dict)\n",
    "    for index, ind in enumerate(individuals):\n",
    "        for fam in ind_to_fams[ind]:\n",
    "            for i, gen in enumerate(gens):\n",
    "                total_prob = 0\n",
    "                for j, obs in enumerate(obss):\n",
    "                    if gen != obs:\n",
    "                    \n",
    "                        if obs == './.':\n",
    "                            p = np.sum(lcr_num[index, :, j])/np.sum(lcr_denom[index, :, j])\n",
    "                        elif lcr_num[index, i, j]==0:\n",
    "                            p = np.sum(lcr_num[:, i, j])/np.sum(lcr_denom[:, i, j])                  \n",
    "                        else:\n",
    "                            p = lcr_num[index, i, j]/lcr_denom[index, i, j]\n",
    "                        error_rates['%s.%s' % (fam, ind)]['-log10(P[obs=%s|true_gen=%s])' % (obs, gen)] = -np.log10(p)\n",
    "                        total_prob += p\n",
    "                    \n",
    "    \n",
    "                # make sure total prob sums to 1\n",
    "                assert total_prob<1\n",
    "                error_rates['%s.%s' % (fam, ind)]['-log10(P[obs=%s|true_gen=%s])' % (gen, gen)] = -np.log10(1-total_prob)\n",
    "\n",
    "    json.dump(error_rates, f, indent=4)\n",
    "    \n",
    "with open('%s/sequencing_error_rates/HCR_errors.json' % data_dir, 'w+') as f:\n",
    "    error_rates = defaultdict(dict)\n",
    "    for index, ind in enumerate(individuals):\n",
    "        for fam in ind_to_fams[ind]:\n",
    "            for i, gen in enumerate(gens):\n",
    "                total_prob = 0\n",
    "                for j, obs in enumerate(obss):\n",
    "                    if gen != obs:\n",
    "                        if obs == './.':\n",
    "                            p = np.sum(hcr_num[index, :, j])/np.sum(hcr_denom[index, :, j])\n",
    "                        elif hcr_num[index, i, j]==0:\n",
    "                            p = np.sum(hcr_num[:, i, j])/np.sum(hcr_denom[:, i, j])               \n",
    "                        else:\n",
    "                            p = hcr_num[index, i, j]/hcr_denom[index, i, j]\n",
    "                        error_rates['%s.%s' % (fam, ind)]['-log10(P[obs=%s|true_gen=%s])' % (obs, gen)] = -np.log10(p)\n",
    "                        total_prob += p\n",
    "                    \n",
    "                # make sure total prob sums to 1\n",
    "                assert total_prob<1\n",
    "                error_rates['%s.%s' % (fam, ind)]['-log10(P[obs=%s|true_gen=%s])' % (gen, gen)] = -np.log10(1-total_prob)\n",
    "\n",
    "            \n",
    "    json.dump(error_rates, f, indent=4)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed02aed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
