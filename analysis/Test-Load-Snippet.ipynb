{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individuals of interest: 2700\n",
      "Sites pulled from vcf: 2363512\n",
      "Removed 199190 sites that are not SNPs\n",
      "Removed 127120 sites that do not pass GATK\n",
      "Removed 30873 sites with >0.010 missing\n",
      "Removed 236594 sites where everyone is hom-ref\n",
      "Changed 386706 calls from missing (-1) to hom-ref (0)\n",
      "Final matrix (2700, 1769735) (1769735,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "from os import listdir\n",
    "\n",
    "chrom = '15'\n",
    "data_dir = '../split_gen_ihart'\n",
    "ped_file = '../data/v34.vcf.ped'\n",
    "\n",
    "# read samples\n",
    "sample_file = '%s/chr.%s.gen.samples.txt' % (data_dir, chrom)\n",
    "with open(sample_file, 'r') as f:\n",
    "    sample_id_to_index = dict([(line.strip(), i) for i, line in enumerate(f)])\n",
    "\n",
    "# read family structure\n",
    "parents = set()\n",
    "children = set()\n",
    "with open(ped_file, 'r') as f:\n",
    "    for line in f:\n",
    "        fam_id, ind_id, dad_id, mom_id, sex, disease_status = line.strip().split('\\t')[:6]\n",
    "        # sex: 1=male, 2=female\n",
    "        # disease status: 1=unaffected, 2=affected\n",
    "        if dad_id != '0' and dad_id in sample_id_to_index:\n",
    "            parents.add(dad_id)\n",
    "        if mom_id != '0' and mom_id in sample_id_to_index:\n",
    "            parents.add(mom_id)\n",
    "        if (dad_id != '0' or mom_id != '0') and ind_id in sample_id_to_index:\n",
    "            children.add(ind_id)\n",
    "        \n",
    "# only interested in children, not parents\n",
    "samples_of_interest = sorted(children - parents)\n",
    "indices = [sample_id_to_index[s] for s in samples_of_interest]\n",
    "print('Individuals of interest:', len(indices))\n",
    "\n",
    "# load genotypes\n",
    "gen_files = sorted([f for f in listdir(data_dir) if ('chr.%s.' % chrom) in f and 'gen.npz' in f])\n",
    "\n",
    "# pull snp positions\n",
    "pos_data = np.load('%s/chr.%s.gen.coordinates.npy' % (data_dir, chrom))\n",
    "is_snp = pos_data[:, 2].astype(bool)\n",
    "snp_positions = pos_data[:, 1]\n",
    "print('Sites pulled from vcf:', snp_positions.shape[0])\n",
    "    \n",
    "# pull PASS (from GATK)\n",
    "is_pass = np.load('%s/chr.%s.pass.npy' % (data_dir, chrom))\n",
    "\n",
    "# Pull data together\n",
    "A = sparse.hstack([sparse.load_npz('%s/%s' % (data_dir, gen_file))[indices, :] for gen_file in gen_files])\n",
    "\n",
    "# only look at snps that PASS GATK filter\n",
    "A = A[:, is_snp & is_pass]\n",
    "snp_positions = snp_positions[is_snp & is_pass]\n",
    "print('Removed %d sites that are not bi-allelic SNPs' % np.sum(~is_snp))\n",
    "print('Removed %d sites that do not pass GATK' % np.sum(is_snp & ~is_pass))\n",
    "\n",
    "# sparse to dense\n",
    "A = A.A\n",
    "\n",
    "# filter out sites with too many missing values\n",
    "missing_cutoff = 0.01\n",
    "lots_of_missing_indices = np.sum(A<0, axis=0) > 0.01*len(indices)\n",
    "A = A[:, ~lots_of_missing_indices]\n",
    "snp_positions = snp_positions[~lots_of_missing_indices]\n",
    "print('Removed %d sites with >%0.3f missing' % (np.sum(lots_of_missing_indices), missing_cutoff))\n",
    "\n",
    "# remove sites where everyone is homref or missing\n",
    "has_variants = np.any(A>0, axis=0)\n",
    "A = A[:, has_variants]\n",
    "snp_positions = snp_positions[has_variants]\n",
    "print('Removed %d sites where everyone is hom-ref' % np.sum(~has_variants))\n",
    "\n",
    "# remaining missing -> hom ref\n",
    "print('Changed %d calls from missing (-1) to hom-ref (0)' % np.sum(A<0))\n",
    "A[A<0] = 0\n",
    "\n",
    "print('Final matrix', A.shape, snp_positions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/OMNI2.5_pruned_positions.txt', 'w+') as outf:\n",
    "    outf.write('# rsid\\tchromosome\\tposition\\n')\n",
    "    for chrom in [str(x) for x in range(1, 23)]:\n",
    "        with open('../../PrunediHART/%s.pruned.bim' % chrom) as f:\n",
    "            for line in f:\n",
    "                pieces = line.strip().split('\\t')\n",
    "                outf.write('.\\t%s\\t%s\\n' % (chrom, pieces[3]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
